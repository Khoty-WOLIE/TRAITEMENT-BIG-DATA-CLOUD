# BIG-DATA-APPLICATION-FRUITS-PYSPARK-AWS-PROJET-FRUITS!

## AperÃ§u de l'entreprise

![AperÃ§u du site web](images/DS_projet9.PNG)

## ğŸ“ Contexte professionnel

En tant que **Data Scientist** chez **Fruits!**, une startup AgriTech spÃ©cialisÃ©e dans la reconnaissance de fruits par robotique intelligente, jâ€™ai Ã©tÃ© missionnÃ© pour reprendre, amÃ©liorer et dÃ©ployer une **chaÃ®ne de traitement Big Data** permettant de prÃ©parer les donnÃ©es dâ€™images de fruits pour de futures prÃ©dictions via un modÃ¨le TensorFlow.

Lâ€™objectif est de traiter des **donnÃ©es massives** issues de lâ€™application mobile de reconnaissance de fruits, Ã  lâ€™aide de **PySpark** sur un environnement **AWS EMR**, tout en assurant **la scalabilitÃ©**, **la conformitÃ© RGPD** et **lâ€™optimisation des coÃ»ts**.

---

## ğŸ¯ Objectifs

- Concevoir une architecture **Big Data scalable** avec **AWS EMR**.
- ComplÃ©ter un pipeline **PySpark** avec rÃ©duction de dimension (**PCA**).
- IntÃ©grer les **poids TensorFlow** pour permettre de lâ€™infÃ©rence distribuÃ©e.
- Garantir la **conformitÃ© RGPD** en traitant les donnÃ©es en Europe.
- PrÃ©parer une **dÃ©monstration technique** de la chaÃ®ne de traitement dans le cloud.

---

## ğŸ§© Ã‰tapes du projet

### ğŸ”¹ Ã‰tape 1 : DÃ©veloppement local de la chaÃ®ne de traitement
- Environnement **PySpark** configurÃ© en local.
- Nettoyage des donnÃ©es images (formatage, filtrage, vectorisation).
- RÃ©duction de dimension par **PCA** pour faciliter le traitement massif.
- ğŸ“„ **Livrable** : Notebook local PySpark avec pipeline PCA complet.

### ğŸ”¹ Ã‰tape 2 : Migration vers AWS EMR (Traitement distribuÃ©)
- CrÃ©ation dâ€™un **cluster EMR** avec configuration optimisÃ©e.
- Utilisation dâ€™**AWS S3** pour le stockage des donnÃ©es et des sorties.
- IntÃ©gration des **poids du modÃ¨le TensorFlow** via **broadcast PySpark** pour lâ€™infÃ©rence.
- ğŸ“„ **Livrable** : Pipeline distribuÃ© opÃ©rationnel sur AWS EMR.

### ğŸ”¹ Ã‰tape 3 : PrÃ©sentation et soutenance
- VÃ©rification des notebooks et scripts (commentaires, reproductibilitÃ©).
- PrÃ©paration dâ€™une **prÃ©sentation technique** (PDF) expliquant :
  - Lâ€™architecture cloud et les services AWS utilisÃ©s
  - La chaÃ®ne de traitement PySpark
  - Les choix technologiques, coÃ»ts et respect du RGPD
- ğŸ“„ **Livrable** : PrÃ©sentation PDF pour la dÃ©monstration finale.

---

## ğŸ› ï¸ Technologies utilisÃ©es

- **PySpark** : Traitement parallÃ¨le des donnÃ©es, PCA
- **TensorFlow** : Utilisation des poids pour infÃ©rence distribuÃ©e
- **AWS EMR** : ExÃ©cution Big Data Ã  grande Ã©chelle
- **AWS S3** : Stockage des donnÃ©es/images et rÃ©sultats
- **AWS IAM** : Gestion des droits dâ€™accÃ¨s
- **PCA** : RÃ©duction de dimension sur donnÃ©es dâ€™images

---

## ğŸ“‚ Livrables

- âœ… Pipeline PySpark local (avec PCA)
- âœ… Pipeline PySpark cloud sur EMR avec diffusion TensorFlow
- âœ… Architecture cloud documentÃ©e (cluster EMR, IAM, S3)
- âœ… PrÃ©sentation de soutenance (format PDF)

---

## ğŸ” RGPD et ScalabilitÃ©

- Traitement des donnÃ©es exclusivement sur **instances EU AWS** pour conformitÃ© RGPD.
- SÃ©curisation des accÃ¨s aux buckets S3 via **politiques IAM**.
- ChaÃ®ne pensÃ©e pour **scalabilitÃ© progressive** aprÃ¨s mise en production de lâ€™app mobile.

---

## âœ… RÃ©sultats

- Pipeline PySpark fonctionnel localement et dans le cloud
- Architecture cloud dÃ©ployÃ©e et reproductible
- DonnÃ©es prÃªtes pour un usage Ã  grande Ã©chelle avec modÃ¨le dâ€™infÃ©rence intÃ©grÃ©
- Soutenance prÃªte Ã  dÃ©montrer le potentiel Big Data du systÃ¨me

---

## ğŸ” AperÃ§u

> Ce projet mâ€™a permis de combiner des compÃ©tences en **traitement Big Data**, **scalabilitÃ© cloud**, **machine learning distribuÃ©** et **gestion des contraintes lÃ©gales (RGPD)** dans un contexte concret dâ€™innovation AgriTech.

---

*Projet rÃ©alisÃ© dans un cadre professionnel simulÃ© avec les responsabilitÃ©s typiques dâ€™un Data Engineer / Data Scientist dans une startup technologique tournÃ©e vers lâ€™IA et le traitement massif de donnÃ©es.*
